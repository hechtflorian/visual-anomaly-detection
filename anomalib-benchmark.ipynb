{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "# -------------------\n",
    "#### Uncomment and run this cell if you need to install the requirements ####\n",
    "\"\"\"\n",
    "!pip install anomalib[full]==1.2.0  # Anomalib version 1.2.0 was used for this benchmark\n",
    "\n",
    "# Fix possible version problems\n",
    "!pip install matplotlib==3.6.0\n",
    "!pip uninstall -y ollama  # Fix anomalib.models import problem (\"cannot import name '_encode_image' from 'ollama._client'\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomalib Benchmark Notebook\n",
    "# ===========================\n",
    "# This notebook allows you to benchmark different anomaly detection models on various datasets with customizable settings.\n",
    "\n",
    "\n",
    "#### Configuration Section (Modify these settings) ####\n",
    "# ------------------------------------------------------------\n",
    "### Choose your dataset:\n",
    "# - \"mvtec\" (MVTec AD dataset)\n",
    "# - \"rubber_mats\" (Dataspree Rubber Mats dataset)\n",
    "# - \"mvtec_multiclass\" (Multi-class MVTec AD dataset)\n",
    "DATASET = \"mvtec\"\n",
    "\n",
    "### For MVTec AD, choose category:\n",
    "# bottle/cable/capsule/carpet/grid/hazelnut/leather/metal_nut/pill/screw/tile/toothbrush/transistor/wood/zipper\n",
    "CATEGORY = \"leather\"  # Only used for MVTec dataset\n",
    "\n",
    "### Image size (width, height)\n",
    "# All Models were tested on: 256x256, 320x320, 448x448. For PatchCore-1% also 360x360, 512x512 were tested\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "### Choose model:\n",
    "# - \"efficientad_s\" (EfficientAD-S)\n",
    "# - \"efficientad_m\" (EfficientAD-M)\n",
    "# - \"fastflow\" (FastFlow)\n",
    "# - \"patchcore_default\" (PatchCore-10%)\n",
    "# - \"patchcore_1percent\" (PatchCore-1%)\n",
    "MODEL = \"patchcore_default\"\n",
    "\n",
    "# Number of epochs (for FastFlow) or steps (for EfficientAD)\n",
    "MAX_EPOCHS = 100  # used for FastFlow\n",
    "MAX_STEPS = 70000 # used for EfficientAD\n",
    "\n",
    "# Batch sizes\n",
    "TRAIN_BATCH_SIZE = 8  # EfficientAD=1 / FastFlow=32 / Patchcore=8\n",
    "EVAL_BATCH_SIZE = 8   # EfficientAD=32 / FastFlow=32 / Patchcore=8\n",
    "\n",
    "### Setup Dataset paths ###\n",
    "# The Benchmark was done on MVTec AD, on Rubber Mats, and on MVTec AD in a multi-class setting\n",
    "# If left empty, the datasets will be downloaded to default locations\n",
    "# If you have the datasets already, specify the paths here\n",
    "\n",
    "## MVTec AD dataset ##\n",
    "MVTEC_ROOT = \"/content/drive/MyDrive/MVTec\"  # Will download automatically if empty\n",
    "\n",
    "\"\"\"\n",
    "## Rubber Mats dataset ##\n",
    "# Needs to be downloaded manually: You can contact Data Spree GmbH for access to the Rubber Mats dataset! https://www.data-spree.com/de/kontakt\n",
    "#RUBBER_MATS_ROOT = \"./dataspree-rubber-mats-dataset-S/datasets/dataspree\"\n",
    "\n",
    "## Multi-class MVTec AD ##\n",
    "# Needs to be downloaded and set up manually for now. \n",
    "# Therefore, you can put together the 5 structures and 10 objects of MVTec AD into Train and Test Folders. Also, Please configure the Anomalib Folder according to your setup.\n",
    "MVTEC_MULTICLASS_ROOT = \"./MVTec-generalized/all\" # Needs to be downloaded and set up manually for now. \n",
    "\n",
    "# configure to match your folder structure\n",
    "TRAIN_DIR = \"train\"\n",
    "TEST_DIR = \"test/defect\"\n",
    "NORMAL_TEST_DIR = \"test/good\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Optional: Comet ML configuration\n",
    "USE_COMET = False  # Set to True to enable Comet ML logging\n",
    "COMET_API_KEY = \"YOUR_API_KEY\"  # Replace with your API key\n",
    "PROJECT_NAME = \"ad-benchmark\"\n",
    "\n",
    "# Optional imports for Comet ML\n",
    "if USE_COMET:\n",
    "    import comet_ml\n",
    "    comet_ml.init(api_key=COMET_API_KEY)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Main imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "import anomalib\n",
    "from anomalib.data import MVTec, Folder\n",
    "from anomalib.models import Patchcore, EfficientAd, Fastflow\n",
    "from anomalib.engine import Engine\n",
    "from anomalib import TaskType\n",
    "from anomalib.data.utils import ValSplitMode, TestSplitMode\n",
    "from anomalib.metrics import AUROC, AUPR, F1Score\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Check environment\n",
    "print(\"\\n=== Environment Information ===\")\n",
    "print(\"Anomalib version:\", anomalib.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda if hasattr(torch.version, 'cuda') else \"Not available\")\n",
    "print(\"GPU availability:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Number of GPU devices:\", torch.cuda.device_count())\n",
    "    print(\"Name of current GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(f\"CUDA memory allocated: {torch.cuda.memory_allocated()}\")\n",
    "    print(f\"CUDA memory reserved: {torch.cuda.memory_reserved()}\")\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "\n",
    "# Set random seed\n",
    "seed_everything(42)\n",
    "print(\"\\n=== Random Seeds ===\")\n",
    "print(f\"PyTorch seed: {torch.initial_seed()}\")\n",
    "print(f\"NumPy seed: {np.random.get_state()[1][0]}\")\n",
    "print(f\"Random seed: {random.getstate()[1][0]}\")\n",
    "\n",
    "\"\"\" \n",
    "Can be uncommented and configured when access to rubber mats dataset is given.\n",
    "# Import Rubber Mats dataset class if needed\n",
    "if DATASET == \"rubber_mats\":\n",
    "    print(\"\\nImporting Rubber Mats dataset class...\")\n",
    "    rubber_mats_path = os.path.dirname(RUBBER_MATS_ROOT) if RUBBER_MATS_ROOT else \"./dataspree-rubber-mats-dataset-S\"\n",
    "    sys.path.append(rubber_mats_path)\n",
    "    try:\n",
    "        from dataspree_anomalib_data import DataspreeDataModule\n",
    "    except ImportError:\n",
    "        print(\"ERROR: Could not import DataspreeDataModule. Please make sure the Rubber Mats dataset is downloaded.\")\n",
    "        print(\"The Dataspree Rubber Mats dataset must be downloaded manually from the official source.\")\n",
    "        raise\n",
    "\"\"\"\n",
    "\n",
    "# Setup Dataset\n",
    "# ------------\n",
    "print(f\"\\n=== Setting up {DATASET} dataset ===\")\n",
    "\n",
    "task = TaskType.CLASSIFICATION\n",
    "seed = 42\n",
    "\n",
    "# Load the appropriate dataset\n",
    "if DATASET == \"mvtec\":\n",
    "    print(f\"Loading MVTec AD dataset, category: {CATEGORY}\")\n",
    "\n",
    "    # If path is not provided, use default download location\n",
    "    if not MVTEC_ROOT:\n",
    "        MVTEC_ROOT = \"./datasets/MVTec\"\n",
    "        print(f\"No path provided for MVTec dataset. Will download to {MVTEC_ROOT} if needed.\")\n",
    "\n",
    "    # MVTec will be automatically downloaded by anomalib if not found at the specified path\n",
    "    datamodule = MVTec(\n",
    "        root=MVTEC_ROOT,\n",
    "        category=CATEGORY,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        num_workers=2,\n",
    "        task=task,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    # ensure that dataset is there. If not it is automatically downloaded here.\n",
    "    datamodule.prepare_data() # you can uncomment this line if download is not needed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Uncomment if acces to Rubber Mats dataset is given.\n",
    "elif DATASET == \"rubber_mats\":\n",
    "    print(\"Loading Rubber Mats dataset\")\n",
    "    if not RUBBER_MATS_ROOT:\n",
    "        print(\"ERROR: Path for Rubber Mats dataset is required\")\n",
    "        print(\"The Dataspree Rubber Mats dataset must be downloaded manually from the official source.\")\n",
    "        raise ValueError(\"RUBBER_MATS_ROOT path must be specified\")\n",
    "\n",
    "    datamodule = DataspreeDataModule(\n",
    "        ds_dataset_id=561,\n",
    "        root=RUBBER_MATS_ROOT,\n",
    "        task=task,\n",
    "        train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        num_workers=2,\n",
    "        seed=seed,\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "elif DATASET == \"mvtec_multiclass\":\n",
    "    print(\"Loading Multi-class MVTec AD dataset\")\n",
    "    if not MVTEC_MULTICLASS_ROOT:\n",
    "        print(\"ERROR: Path for MVTec Multiclass dataset is required\")\n",
    "        print(\"The MVTec Multiclass dataset must be downloaded manually.\")\n",
    "        raise ValueError(\"MVTEC_MULTICLASS_ROOT path must be specified\")\n",
    "\n",
    "    datamodule = Folder(\n",
    "        name=\"MVTec-generalized\",\n",
    "        root=MVTEC_MULTICLASS_ROOT,\n",
    "        normal_dir=TRAIN_DIR,\n",
    "        abnormal_dir=TEST_DIR,\n",
    "        normal_test_dir=NORMAL_TEST_DIR,\n",
    "        task=task,\n",
    "        train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        num_workers=2,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        seed=seed,\n",
    "        val_split_mode=ValSplitMode.SAME_AS_TEST,\n",
    "        normal_split_ratio=None,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset: {DATASET}\")\n",
    "\n",
    "\n",
    "# Setup the datamodule\n",
    "try:\n",
    "    datamodule.setup()\n",
    "    print(\"\\n=== Dataset Information ===\")\n",
    "    print(f\"Total training images: {len(datamodule.train_dataloader().dataset)}\")\n",
    "    print(f\"Total validation images: {len(datamodule.val_dataloader().dataset)}\")\n",
    "    print(f\"Total test images: {len(datamodule.test_dataloader().dataset)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up dataset: {e}\")\n",
    "    if DATASET == \"mvtec\":\n",
    "        print(\"\\nTip: MVTec dataset will be automatically downloaded if not found.\")\n",
    "        print(\"If you're having connection issues, you can manually download the dataset from:\")\n",
    "        print(\"https://www.mvtec.com/company/research/datasets/mvtec-ad\")\n",
    "        print(\"and place it in the specified MVTEC_ROOT directory.\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Setup Model\n",
    "# ----------\n",
    "print(f\"\\n=== Setting up {MODEL} model ===\")\n",
    "\n",
    "# Initialize the selected model\n",
    "if MODEL == \"efficientad_s\":\n",
    "    model = EfficientAd()\n",
    "elif MODEL == \"efficientad_m\":\n",
    "    from anomalib.models.image.efficient_ad.torch_model import EfficientAdModelSize\n",
    "    model = EfficientAd(model_size=EfficientAdModelSize.M)\n",
    "elif MODEL == \"fastflow\":\n",
    "    model = Fastflow(backbone=\"wide_resnet50_2\")\n",
    "elif MODEL == \"patchcore_default\":\n",
    "    model = Patchcore()\n",
    "elif MODEL == \"patchcore_1percent\":\n",
    "    model = Patchcore(\n",
    "        backbone=\"wide_resnet101_2\",\n",
    "        layers=(\"layer2\", \"layer3\"),\n",
    "        pre_trained=True,\n",
    "        coreset_sampling_ratio=0.01,\n",
    "        num_neighbors=9,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model: {MODEL}\")\n",
    "\n",
    "\n",
    "# Setup Logger (optional)\n",
    "# ---------------------\n",
    "if USE_COMET:\n",
    "    from anomalib.loggers import AnomalibCometLogger\n",
    "\n",
    "    # Generate experiment name based on settings\n",
    "    if DATASET == \"mvtec\":\n",
    "        experiment_name = f\"{MODEL}_{CATEGORY}_{IMAGE_SIZE[0]}\"\n",
    "    else:\n",
    "        experiment_name = f\"{MODEL}_{DATASET}_{IMAGE_SIZE[0]}\"\n",
    "\n",
    "    comet_logger = AnomalibCometLogger(\n",
    "        project_name=PROJECT_NAME,\n",
    "        experiment_name=experiment_name\n",
    "    )\n",
    "    logger = comet_logger\n",
    "else:\n",
    "    logger = None\n",
    "\n",
    "\n",
    "# Setup Callbacks\n",
    "# --------------\n",
    "# Create results directory\n",
    "results_dir = \"./results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "if MODEL in [\"efficientad_s\", \"efficientad_m\", \"fastflow\"]:\n",
    "    # These models benefit from callbacks\n",
    "    save_dir = f\"{results_dir}/{MODEL}\"\n",
    "    if DATASET == \"mvtec\":\n",
    "        save_dir += f\"/MVTec/{CATEGORY}\"\n",
    "    else:\n",
    "        save_dir += f\"/{DATASET}\"\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"image_AUROC\",\n",
    "        mode=\"max\",\n",
    "        dirpath=save_dir,\n",
    "        save_top_k=1,\n",
    "        save_last=True,\n",
    "    )\n",
    "    callbacks = [checkpoint_callback]\n",
    "else:\n",
    "    # PatchCore doesn't need callbacks, and needs only 1 Epoch\n",
    "    callbacks = None\n",
    "    checkpoint_callback = None\n",
    "\n",
    "\n",
    "# Setup Engine\n",
    "# -----------\n",
    "print(\"\\n=== Setting up training engine ===\")\n",
    "\n",
    "# Configure engine based on model\n",
    "engine_kwargs = {\n",
    "    \"task\": task,\n",
    "    \"image_metrics\": {\n",
    "        \"Precision\": {\n",
    "            \"class_path\": \"torchmetrics.Precision\",\n",
    "            \"init_args\": {\"task\": \"binary\"},\n",
    "        },\n",
    "        \"Recall\": {\n",
    "            \"class_path\": \"torchmetrics.Recall\",\n",
    "            \"init_args\": {\"task\": \"binary\"},\n",
    "        },\n",
    "        \"AUROC\": {\n",
    "            \"class_path\": \"torchmetrics.AUROC\",\n",
    "            \"init_args\": {\"task\": \"binary\"},\n",
    "        },\n",
    "        \"F1Score\": {\n",
    "            \"class_path\": \"torchmetrics.F1Score\",\n",
    "            \"init_args\": {\"task\": \"binary\"},\n",
    "        },\n",
    "        \"AUPR\": {\n",
    "            \"class_path\": \"torchmetrics.AveragePrecision\",\n",
    "            \"init_args\": {\"task\": \"binary\"},\n",
    "        },\n",
    "    },\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"devices\": 1,\n",
    "    \"logger\": logger,\n",
    "}\n",
    "\n",
    "\n",
    "if callbacks:\n",
    "    engine_kwargs[\"callbacks\"] = callbacks\n",
    "\n",
    "if MODEL == \"fastflow\":\n",
    "    engine_kwargs[\"max_epochs\"] = MAX_EPOCHS\n",
    "    #engine_kwargs[\"log_every_n_steps\"] = 2\n",
    "\n",
    "if MODEL in [\"efficientad_s\", \"efficientad_m\"]:\n",
    "    engine_kwargs[\"max_steps\"] = MAX_STEPS\n",
    "\n",
    "engine = Engine(**engine_kwargs)\n",
    "\n",
    "\n",
    "# Train Model\n",
    "# ----------\n",
    "print(\"\\n=== Training model ===\")\n",
    "try:\n",
    "    engine.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "    # Print checkpoint information if applicable\n",
    "    if MODEL in [\"efficientad_s\", \"efficientad_m\", \"fastflow\"] and checkpoint_callback:\n",
    "        print(f\"\\nBEST model saved: {checkpoint_callback.best_model_path}\")\n",
    "        print(f\"Last model saved: {checkpoint_callback.last_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Test Model\n",
    "# ---------\n",
    "print(\"\\n=== Testing model ===\")\n",
    "test_kwargs = {\n",
    "    \"model\": model,\n",
    "    \"datamodule\": datamodule,\n",
    "}\n",
    "\n",
    "if MODEL in [\"efficientad_s\", \"efficientad_m\", \"fastflow\"] and checkpoint_callback and checkpoint_callback.best_model_path:\n",
    "    test_kwargs[\"ckpt_path\"] = checkpoint_callback.best_model_path\n",
    "\n",
    "try:\n",
    "    test_results = engine.test(**test_kwargs)\n",
    "    print(\"\\nTest Results:\")\n",
    "    for metric_name, value in test_results[0].items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"{metric_name}: {value:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during testing: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Measure Model Efficiency\n",
    "# ----------------------\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n=== Measuring model efficiency ===\")\n",
    "\n",
    "    # FPS and Latency measurement\n",
    "    def measure_fps_latency(model, input_size=(1, 3, 256, 256), num_runs=100, exclude_first=10):\n",
    "        model.eval().cuda()\n",
    "        x = torch.rand(*input_size).cuda()\n",
    "        time_list = []\n",
    "\n",
    "        for _ in tqdm(range(num_runs), desc=\"Measuring FPS and Latency\"):\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                model(x)\n",
    "            torch.cuda.synchronize()\n",
    "            time_list.append(time.time() - start_time)\n",
    "\n",
    "        time_list = time_list[exclude_first:]\n",
    "        if not time_list:\n",
    "            raise ValueError(f\"`exclude_first` ({exclude_first}) is too high for `num_runs` ({num_runs}).\")\n",
    "\n",
    "        latency_ms = (sum(time_list) / len(time_list)) * 1000\n",
    "        fps = 1 / (sum(time_list) / len(time_list))\n",
    "\n",
    "        return fps, latency_ms\n",
    "\n",
    "    # Throughput measurement\n",
    "    def measure_throughput(model, input_size=(16, 3, 256, 256), num_runs=100, batch_size=16, exclude_first=10):\n",
    "        model.eval().cuda()\n",
    "        x = torch.rand(*input_size).cuda()\n",
    "        throughput_list = []\n",
    "\n",
    "        for _ in tqdm(range(num_runs), desc=\"Measuring Throughput\"):\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                model(x)\n",
    "            torch.cuda.synchronize()\n",
    "            throughput_list.append(time.time() - start_time)\n",
    "\n",
    "        throughput_list = throughput_list[exclude_first:]\n",
    "        throughput = (batch_size * len(throughput_list)) / sum(throughput_list)\n",
    "\n",
    "        return throughput\n",
    "\n",
    "    # Measure performance metrics (reduced number of runs demo. Use num_runs=1000 for proper results.)\n",
    "    try:\n",
    "        input_size = (1, 3, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "        fps, latency_ms = measure_fps_latency(model, input_size=input_size, num_runs=100)\n",
    "        fps = round(fps, 2)\n",
    "        latency_ms = round(latency_ms, 2)\n",
    "\n",
    "        input_size_throughput = (16, 3, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "        throughput = measure_throughput(model, input_size=input_size_throughput, num_runs=100)\n",
    "        throughput = round(throughput, 2)\n",
    "\n",
    "        # Print results\n",
    "        print(\"\\n=== Performance Metrics ===\")\n",
    "        print(f\"FPS: {fps}\")\n",
    "        print(f\"Latency: {latency_ms} ms\")\n",
    "        print(f\"Throughput: {throughput} images/second\")\n",
    "\n",
    "        # Log metrics to Comet if enabled\n",
    "        if USE_COMET:\n",
    "            comet_logger.experiment.log_metric(name=\"FPS\", value=fps)\n",
    "            comet_logger.experiment.log_metric(name=\"Latency(ms)\", value=latency_ms)\n",
    "            comet_logger.experiment.log_metric(name=\"Throughput(img/s)\", value=throughput)\n",
    "\n",
    "            # End experiment logging\n",
    "            comet_logger.experiment.end()\n",
    "    except Exception as e:\n",
    "        print(f\"Error measuring performance: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping performance measurements as CUDA is not available\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Benchmark completed successfully ===\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
